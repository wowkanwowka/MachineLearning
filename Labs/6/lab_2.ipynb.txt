{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Лабораторная работа 2. Обучение без учителя\n",
    "\n",
    "Результат лабораторной работы − отчет. Мы предпочитаем принимать отчеты в формате ноутбуков IPython (ipynb-файл). Постарайтесь сделать ваш отчет интересным рассказом, последовательно отвечающим на вопросы из заданий. Помимо ответов на вопросы, в отчете также должен быть код, однако чем меньше кода, тем лучше всем: нам − меньше проверять, вам — проще найти ошибку или дополнить эксперимент. При проверке оценивается четкость ответов на вопросы, аккуратность отчета и кода.\n",
    "\n",
    "### Оценивание и штрафы\n",
    "Каждая из задач имеет определенную «стоимость» (указана в скобках около задачи). Максимально допустимая оценка за работу — 15 баллов. Сдавать задание после указанного срока сдачи нельзя. «Похожие» решения считаются плагиатом и все задействованные студенты (в том числе те, у кого списали) не могут получить за него больше 0 баллов и понижают карму (подробнее о плагиате см. на странице курса). Если вы нашли решение какого-то из заданий в открытом источнике, необходимо прислать ссылку на этот источник (скорее всего вы будете не единственным, кто это нашел, поэтому чтобы исключить подозрение в плагиате, нам необходима ссылка на источник).\n",
    "\n",
    "### Правила сдачи\n",
    "Выполненную работу следует отправить в систему Anytask. Более подробно о системе можно почитать на странице курса. Название отправляемого файла должно иметь следующий формат: Surname_Name_Group_NN.ipynb, где NN — номер лабораторной работы. Например, Kozlova_Anna_CS_02.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кластеризация\n",
    "\n",
    "![Digits](https://i.imgur.com/DINSGXS.png)\n",
    "\n",
    "Задача [кластеризации](https://en.wikipedia.org/wiki/Cluster_analysis) данных является одним из примеров задач обучения \"без учителя\". Она заключается в разбиении множества объектов на кластеры, при этом предполагается, что внутри одного кластера будут находиться похожие между собой объекты. Одним из примеров методов кластеризации является алгоритм [KMeans](https://en.wikipedia.org/wiki/K-means_clustering).\n",
    "\n",
    "### Выбор числа кластеров\n",
    "\n",
    "Для некоторых алгоритмов кластеризации число кластеров является гиперпараметром (например, в случае KMeans). Поэтому для выбора количества кластеров может быть использован следующий подход: при фиксированной метрике качества для разного числа кластеров вычисляется кластеризация и выбирается то количество кластеров, начиная с которого качество \"стабилизируется\".\n",
    "\n",
    "### Метрики качества\n",
    "\n",
    "Оценивание качества построенной кластеризации не всегда тривиальная задача, так как следует учитывать такие факты как:\n",
    " - объекты одного кластера должны быть более похожи, чем объекты других кластеров, относительно некоторой заданной метрики похожести\n",
    " - метрика не должна учитывать абсолютные значения меток объектов, попавших в кластер (в случае, если истинные метки известны)\n",
    "\n",
    "При выполнении задания для оценки качества получившейся кластеризации воспользуемся следующими метриками:\n",
    " - [Homogeneity и Completeness](http://scikit-learn.org/stable/modules/clustering.html#homogeneity-completeness-and-v-measure) \n",
    " - [Adjusted Rand index](http://scikit-learn.org/stable/modules/clustering.html#adjusted-rand-index) \n",
    " - [Silhouette Coefficient](http://scikit-learn.org/stable/modules/clustering.html#silhouette-coefficient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите набор данных [digits](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html). Перед применением алгоритмов не забудьте перемешать изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1. (1 балл)** Кластеризуйте изображения при помощи алгоритма [KMeans](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html): \n",
    "* Подберите число кластеров для некоторой фиксированной метрики из указанных выше. \n",
    "* Рассмотрите различные способы выбора начального приближения (параметр *init*). \n",
    "* Оцените качество получившейся кластеризации используя все описанные выше метрики. \n",
    "* Визуализируйте изображения, соответствующие центроидам лучшей кластеризации. \n",
    "* Визуализируйте несколько изображений, которые во всех случаях были отнесены к неправильному кластеру (объект назовем ошибочно отнесенным, если он имеет иную метку класса, нежели большая часть объектов в кластере). Можете ли вы пояснить почему так произошло?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не всегда бывает удобно работать с полной матрицей объект-признак, например, для случая визуализации данных. В одной из предыдущих лабораторных работ был рассмотрен метод уменьшения размерности *PCA*. Вот [здесь](http://scikit-learn.org/stable/auto_examples/manifold/plot_lle_digits.html#example-manifold-plot-lle-digits-py) было показано сравнение различных способов сжатия размерности для проекции на плоскость. На изображениях видно, что некоторые преобразования дают неплохую картину и похожие объекты расположены близко друг к другу. Посмотрим, поможет ли это на практике.\n",
    " \n",
    "**Задание 2. (2.5 балла)** Примените преобразования [PCA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) и [tSNE](http://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) (для числа компонент 2), после чего подайте полученные представления объектов на вход алгоритмам KMeans, [DBSCAN](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html) и [Birch](http://scikit-learn.org/stable/modules/generated/sklearn.cluster.Birch.html). \n",
    "* Сравните новые и предыдущие результаты. \n",
    "* Нашлась ли пара \"представление\"—\"алгоритм\", превосходящая другие по всем метрикам? \n",
    "* Являются ли все три метрики согласованными? Можете ли вы объяснить почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3. (0.5 балла)** Ответьте на следующие вопросы:\n",
    "* В чём преимущества и недостаки каждого из рассмотренных алгоритмов кластеризации? Ответ обоснуйте.\n",
    "* Приведите примеры данных, для которых использование каждого из алгоритмов будет наиболее обосновано с точки зрения качества и/или производительности? В этом задании будет достаточно описать какими должны быть данные, приводить примеры конкретных датасетов не нужно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Частичное обучение\n",
    "\n",
    "![](https://i.imgur.com/C6HjiXq.png)\n",
    "\n",
    "Качество unsupervised методов можно существенно улучшить, зная правильные ответы хотя бы для небольшой части выборки. Методы такого рода называются _частичным обучением (semi-supervised learning)_. Более подробно про реализацию таких методов в sklearn можно прочитать в разделе [semi-supervised](http://scikit-learn.org/stable/modules/label_propagation.html#semi-supervised).\n",
    "\n",
    "Загрузите датасет [Wine](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html) и создайте из него выборку, где для каждого класса имеется по одному объекту с известным ответом, а ответы на остальных объектах равны -1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4. (1 балл)** Обучите [LabelSpreading](http://scikit-learn.org/stable/modules/generated/sklearn.semi_supervised.LabelSpreading.html) на этих данных, рассмотрев различные значения параметра **kernel** (*knn*, *rbf*). Посчитайте качество полученной разметки для каждого класса (в качестве метрик используйте точность и полноту). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 5. (0.5 балла)** Отобразите объекты вместе с верными и предсказанными ответами на двумерном графике, использовав [PCA](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) с 2 компонентами. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 6. (0.5 балла)** Попробуйте запустить алгоритм несколько раз, отмечая известными различные объекты, посчитайте качество и визуализируйте результаты. Можно ли сказать что алгоритм сильно зависит от известных начальных объектов? Есть ли класс, для которого это больше всего заметно?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тематическое моделирование\n",
    "\n",
    "![](http://imgur.com/S8WgwBp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тематическое моделирование является популярным инструментом анализа текстов. Задача заключается в поиске тем $T$, которые хорошо бы описывали документы $D$ со словарём $W$. Большинство тематических моделей оперирует данными в формате \"мешка слов\", т.е. учитывают только частоты слов в документах, а не их порядок. Одной из простейших тематических моделей является [PLSA](https://en.wikipedia.org/wiki/Probabilistic_latent_semantic_analysis), которая приводит к задаче стохастического матричного разложения: \n",
    "\n",
    "$$F \\approx \\Phi \\times \\Theta$$\n",
    "где\n",
    "- $F_{W \\times D}$— матрица распределений слов в документах (нормированные частоты)\n",
    "- $\\Phi_{W \\times T}$ — матрица распределений слов в темах (модель)\n",
    "- $\\Theta_{T \\times D}$ — матрица распределений тем в документах (результат применения модели к обучающим данным)\n",
    "\n",
    "Можно сказать, что алгоритмы тематического моделирования производят мягкую бикластеризацию данных:\n",
    " - *мягкую*, так как объекты относятся не строго к одному кластеру, а к нескольким с разными вероятностями\n",
    " - *бикластеризацию*, так как модель одновременно кластеризует слова по темам и темы по документам."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EM-алгоритм\n",
    "\n",
    "![](http://imgur.com/EeIuI1T.png)\n",
    "\n",
    "С вероятностной точки зрения, задача обучения модели PLSA ставится как максимизация неполного правдоподобия по параметам $\\Phi$ и $\\Theta$. ЕМ-алгоритм для модели PLSA заключается в повторении двух шагов:\n",
    "\n",
    "- **Е-шаг** — оценка распределений тем для каждого слова в каждом документе по параметрам $\\Phi$ и $\\Theta$ (шаг 6);\n",
    "- **М-шаг** — обновление параметров $\\Phi$ и $\\Theta$ на основе полученных оценок (шаги 7 и 9).\n",
    "\n",
    "Существуют различные модификации итерационного процесса, позволяющие снизить расходы по памяти. В данном случае, мы избежим хранения трехмерной матрицы $p_{tdw}$, сразу пересчитывая $\\Theta$ для текущего документа и аккумулируя счетчики $n_{wt}$ для последующего пересчета $\\Phi$.\n",
    "\n",
    "Псевдокод алгоритма записывается следующим образом:\n",
    "\n",
    "1. Инициализировать $\\phi_{wt}^0$ для всех $w \\in W$, $t \\in T$ и $\\theta_{td}^0$ для всех $t \\in T$, $d \\in D$\n",
    "2. Внешний цикл по итерациям $i = 1 ... max\\_iter$:\n",
    "3. $\\quad$ $n_{wt}^i := 0$, $n_t^i := 0$ для всех $w \\in W$ и $t \\in T$ \n",
    "4. $\\quad$ Внутренний цикл по документам $d \\in D$  \n",
    "5. $\\qquad$ $Z_w := \\sum_{t \\in T} \\phi_{wt}^{i-1}\\theta_{td}^{i-1}$ для всех $w \\in d$ $\\cfrac{}{}$\n",
    "6. $\\qquad$ $p_{tdw} := \\cfrac{ \\phi_{wt}^{i-1}\\theta_{td}^{i-1} }{ Z_w }$ (**E-шаг**)\n",
    "7. $\\qquad$ $\\theta_{td}^{i} := \\cfrac{ \\sum_{w \\in d} n_{dw} p_{tdw} }{ n_d }$ для всех $t \\in T$ (**M-шаг**)\n",
    "8. $\\qquad$ Увеличить $n_{wt}^i$ и $n_t^i$ на $n_{dw} p_{tdw}$ для всех $w \\in W$ и $t \\in T$\n",
    "9. $\\quad \\phi_{wt}^i := \\cfrac{n_{wt}^i}{n_t^i}$ для всех $w \\in W$ и $t \\in T$ (**M-шаг**)\n",
    "\n",
    "Обозначения:\n",
    " - $p_{tdw}$ — вероятность темы $t$ для слова $w$ в документе $d$\n",
    " - $\\phi_{wt}$ — элемент матрицы $\\Phi$, соответствующий вероятности слова $w$ в теме $t$\n",
    " - $\\theta_{td}$ — элемент матрицы $\\Theta$, соответствующий вероятности темы $t$ в документе $d$\n",
    " - $n_{wt}$ — элемент матрицы счётчиков отнесения слова $w$ к теме $t$ (путем нормирования этой матрицы получается матрица $\\Phi$)\n",
    " - $Z_w$ — элемент вектора вспомогательных переменных, соответствующий слову $w$\n",
    " - $n_t$ — вектор нормировочных констант для матрицы $n_{wt}$\n",
    " - $n_d$ — вектор нормировочных констант для матрицы $n_{dw}$\n",
    " - $n$ — суммарное число слов в коллекции\n",
    " \n",
    "###  Оценка качества\n",
    "\n",
    "Для оценивания качества построенной модели и контроля сходимости процесса обучения обычно используют [перплексию](http://www.machinelearning.ru/wiki/images/8/88/Voron-iip9-talk.pdf):\n",
    "\n",
    "$$\\mathcal{P} = \\exp\\bigg(- \\frac{\\mathcal{L}}{n} \\bigg) = \\exp\\bigg(- \\cfrac{1}{n}\\sum_{d \\in D}\\sum_{w \\in d} n_{dw} \\ln \\big(\\sum_{t \\in T}\\phi_{wt}\\theta_{td} \\big)\\bigg)$$\n",
    "\n",
    "Это традиционная мера качества в тематическом моделировании, которая основана на правдоподобии модели $\\mathcal{L}$. Число итераций $max\\_iter$ в алгоритме обучения следует выбирать достаточным для того, чтобы перплексия перестала существенно убывать. Однако известно, что перплексия плохо отражает интерпретируемость найденных тем, поэтому помимо нее обычно используются дополнительные меры или экспертные оценки.\n",
    "\n",
    "### Рекомендации к реализации\n",
    "- При делении на нулевые значения нужно просто заменить частное на ноль.\n",
    "- ЕМ-алгоритм стоит реализовывать с использованием векторных операций. Для проверки корректности реализации сперва можно написать скалярную версию, после чего векторизовать её, удостоверившись, что обе реализации дают одинаковый результат. Невекторизованный алгоритм может работать в сотни раз медленнее векторизованного, и его использование может привести к невозможности выполнения задания.\n",
    "- Итерационный процесс следует начинать, инициализировав матрицы $\\Phi$ и $\\Theta$. Инициализация может быть случайной, важно не забыть отнормировать столбцы матриц.\n",
    "- Неэффективная реализация перплексии может в разы замедлить работу алгоритма."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите [коллекцию писем Х. Клинтон](https://www.dropbox.com/s/je8vq5fsb8xpy2u/hillary_data.zip?dl=0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Извлеките полные тексты писем из файла *Emails.csv* и подготовьте данные в формате \"мешка слов\" с помощью функции  [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) пакета sklearn. Рекомендуется произвести фильтрацию слов по частотности для удаления слишком редких и стоп-слов (рекомендованный нижний порог в пределах 10 и верхний 400-600)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 7. (4 балла)** Реализуйте описанный выше ЕМ-алгоритм для модели $PLSA$ и добавьте в вашу реализацию подсчёт перплексии. Примените ваш алгоритм к подготовленным данным, рассмотрев число тем T = 5. \n",
    "* Постройте график значения перплексии в зависимости от итерации (убедитесь в корректности реализации: график перплексии должен быть невозрастающим). \n",
    "* Выведите для каждой темы топ-20 наиболее вероятных слов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 8. (2 балла)** Рассмотрите большее число тем (10, 20) и несколько различных начальных приближений. Проанализируйте результаты и ответьте на следующие вопросы: \n",
    "- Mожно ли сказать, что конкретность каждой темы изменяется с ростом их числа?\n",
    "- Устойчив ли алгоритм к начальному приближению на примере идентичности топовых слов в соответствующих темах?\n",
    "- Отражает ли перплексия качество получаемых моделей? В чём заключается причина хорошего/плохого соответствия?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Модель LDA и визуализация\n",
    "\n",
    "Модель [LDA](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) является наиболее популярной тематической моделью. Единственное отличие от модели PLSA заключается в введении априорных распределений Дирихле на столбцы матриц $\\Phi$ и $\\Theta$, которое может способствовать дополнительному сглаживанию или разреживанию параметров.\n",
    "\n",
    "В этом задании предлагается воспользоваться реализацией модели [LdaModel](https://radimrehurek.com/gensim/models/ldamodel.html), обучение которой основано на вариационном байесовском выводе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнение задания потребует установки пакетов [gensim](https://radimrehurek.com/gensim/install.html) и [pyldavis 2.0](https://pyldavis.readthedocs.io/en/latest/readme.html#installation).\n",
    "\n",
    "\n",
    "Для обучения *LdaModel* и её последующей визуализации потребуется словарь формата gensim, который можно получить следующей командой\n",
    "\n",
    "    dictionary = gensim.corpora.Dictionary.from_corpus(corpora, vocab_dict)\n",
    "\n",
    "где *corpora* содержит полученное с помощью gensim представление коллекции, а *vocab_dict* — это dict, полученный после работы CountVectorizer, ставящий в соответствие каждому номеру строки в матрице данных само слово в виде строки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовьте данные в формате, подходящем для *gensim* (полное [API](https://radimrehurek.com/gensim/apiref.html) gensim). [Пример обработки вывода](https://gist.github.com/aronwc/8248457) *CountVectorizer* для gensim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 9. (1.5 балла)** Примените [LdaModel](https://radimrehurek.com/gensim/models/ldamodel.html) к подготовленным данным (рекомендуется задать заведомо большое число итераций в параметре *passes*, например, 30). Визуально сравните полученные темы по топ-20 наиболее вероятным словам с темами, полученными вашей реализацией ЕМ-алгоритма (нерегуляризованного). Какая из моделей даёт более интерпретируемые темы и почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 10. (1.5 балл)** Визуализируйте модель из gensim с помощью библиотеки *ldavis* ([API](http://pyldavis.readthedocs.io/en/latest/modules/API.html) LDAvis для работы с gensim), [пример использования](https://github.com/bmabey/pyLDAvis/blob/master/notebooks/pyLDAvis_overview.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
